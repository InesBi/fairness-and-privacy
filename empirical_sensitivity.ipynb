{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "empirical_sensitivity.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InesBi/fairness-and-privacy/blob/master/empirical_sensitivity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09zMyIxCEy44",
        "colab_type": "text"
      },
      "source": [
        "import statments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHU7nHAUE6LZ",
        "colab_type": "code",
        "outputId": "298a14f8-3c2f-46ce-9d73-665ff1e597d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!git clone https://github.com/ecreager/ammi-fairness-and-privacy.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ammi-fairness-and-privacy' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PmUheTwFB0l",
        "colab_type": "code",
        "outputId": "f75a84e1-ad61-4162-9f5e-0b76ce375c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/ammi-fairness-and-privacy/assignment2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ammi-fairness-and-privacy/assignment2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D7aa5mUEy46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Empirical Sensitivity.\"\"\"\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from utils import get_data_loaders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0DqweckEy4-",
        "colab_type": "text"
      },
      "source": [
        "your code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITJ2VOVdEy4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_hist(array_of_empirical_sensitivities, n, lmbda, name):\n",
        "    if not isinstance(array_of_empirical_sensitivities, np.ndarray):\n",
        "        raise ValueError('array_of_empirical_sensitivities should be a np.ndarray.')\n",
        "    if not isinstance(name, str):\n",
        "        raise ValueError('name should be a str')\n",
        "\n",
        "    import matplotlib\n",
        "    matplotlib.use('Agg')\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    ################################################################\n",
        "    # TODO(student): replace below with correct theoretical max sensitivity\n",
        "    max_theoretical_sensitivity = -1.\n",
        "    ################################################################\n",
        "\n",
        "    num_bins = 20\n",
        "    dirname = './figs'\n",
        "    filename = os.path.join(dirname, name) + '.histogram.png'\n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_xscale('log')\n",
        "    bin_values, _, _ = ax.hist(array_of_empirical_sensitivities, \n",
        "            num_bins, label='empirical sensitivities')\n",
        "    ax.set_title('histogram of sensitivities: ' + name)\n",
        "    ax.axvline(x=max_theoretical_sensitivity, color='r', linestyle='dashed', linewidth=2,\n",
        "            label='theoretical max sensitivity')\n",
        "    ax.legend()\n",
        "    fig.savefig(filename)\n",
        "    return filename\n",
        "\n",
        "\n",
        "def plot_extreme_neighbors(sensitivities, list_of_neighboring_examples, name):\n",
        "    \"\"\"Plots to disk the neighboring-example pairs with the most and least empirical sensitivity\n",
        "    \n",
        "    Note on the data structures used: \n",
        "        sensitivities: a np.ndarray containing empirical sensitivities for each run\n",
        "        list_of_neighboring_examples: a list of neighboring example pairs, one for each run. in other words:\n",
        "        \n",
        "        list_of_neighboring_examples = [\n",
        "            neighboring_example_1, \n",
        "            neighboring_example_2,  \n",
        "            ...\n",
        "            neighboring_example_n,\n",
        "            ]\n",
        "            \n",
        "        where each tuple in the list represents the data diff between the neighboring \n",
        "        datasets and is formatted like this:\n",
        "        \n",
        "        neighboring_example_i = (\n",
        "            (neighbor_img_i, neighbor_label_i),\n",
        "            (neighbor_img_i_prime, neighbor_label_i_prime),\n",
        "        )\n",
        "        \n",
        "        See utils.py if you are still confused.\n",
        "    \"\"\"\n",
        "    if not isinstance(sensitivities, np.ndarray):\n",
        "        raise ValueError('sensitivies should be a np.ndarray.')\n",
        "    first_neighbor_pair = list_of_neighboring_examples[0]\n",
        "    if not isinstance(list_of_neighboring_examples, list) or not isinstance(first_neighbor_pair, tuple) \\\n",
        "            or not isinstance(first_neighbor_pair[0][0], torch.Tensor):\n",
        "        raise ValueError('list_of_neighboring_examples should be a list of tuple pairs, where tuple contains img tensors')\n",
        "    if not isinstance(name, str):\n",
        "        raise ValueError('name should be a str')\n",
        "\n",
        "    import matplotlib\n",
        "    matplotlib.use('Agg')\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO(student)\n",
        "    #\n",
        "    # using list_of_empirical_sensitivies and neighboring_examples, create two image plots\n",
        "    # 1) side-by-side images for neighbor-pair that maximizes sensitivity\n",
        "    # 2) side-by-side images for neighbor-pair that minimizes sensitivity\n",
        "    #\n",
        "    # matplotlib.subplots and matplotlib.imshow may come in handy\n",
        "    \n",
        "    #filenames = None, None\n",
        "    #raise NotImplementedError\n",
        "    pil_transform = transforms.ToPILImage()\n",
        "    max_idx = np.argmax(sensitivities)\n",
        "    min_idx = np.argmin(sensitivities)\n",
        "    max_neighbor_example = list_of_neighboring_examples[max_idx]\n",
        "    min_neighbor_example = list_of_neighboring_examples[min_idx]\n",
        "    max_neighbor, max_neighbor_prime = max_neighbor_example\n",
        "    min_neighbor, min_neighbor_prime = min_neighbor_example\n",
        "    \n",
        "    max_neighbor_img, max_neighbor_target = max_neighbor\n",
        "    max_neighbor_prime_img, max_neighbor_prime_target = max_neighbor_prime\n",
        "    \n",
        "    min_neighbor_img, min_neighbor_target = min_neighbor\n",
        "    min_neighbor_prime_img, min_neighbor_prime_target = min_neighbor_prime\n",
        "    \n",
        "    dirname = \"./figs\"\n",
        "    filename1 = os.path.join(dirname, name) + \".max_sensitivity.png\"\n",
        "    filename2 = os.path.join(dirname, name) + \".min_sensitivity\"\n",
        "    filenames = filename1, filename2\n",
        "    \n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)\n",
        "    fig1, axes1 = plt.subplots(1,2,figsize=(9,3))\n",
        "    axes1[0].imshow(pil_transform(max_neighbor_img))\n",
        "    axes1[1].imshow(pil_transform(max_neighbor_prime_img))\n",
        "    fig1.suptitle(\"maximum sensitivity:\" + name)\n",
        "    fig1.savefig(filename1)\n",
        "    \n",
        "    \n",
        "    fig2, axes2 = plt.subplots(1,2,figsize = (9,3))\n",
        "    axes2[0].imshow(pil_transform(min_neighbor_img))\n",
        "    axes2[1].imshow(pil_transform(min_neighbor_prime_img))\n",
        "    fig2.suptitle(\"minimum sensitivity:\" + name)\n",
        "    fig2.savefig(filename2)\n",
        "    ############################################################################\n",
        "\n",
        "    return filenames\n",
        "\n",
        "\n",
        "def compute_empricial_sensivity(train_loader, neighbor_loader,\n",
        "        num_epochs, learning_rate, lmbda, model_seed=None):\n",
        "    ############################################################################\n",
        "    # TODO(student)\n",
        "    #\n",
        "    # your code here...\n",
        "    #\n",
        "    train_param = nonprivate_logistic_regression(train_loader, num_epochs, learning_rate, lmbda,model_seed)\n",
        "    neighbor_param = nonprivate_logistic_regression(neighbor_loader, num_epochs, learning_rate, lmbda, model_seed)\n",
        "    \n",
        "    sensitivity = torch.norm(train_param[\"weight\"] - neighbor_param[\"weight\"], p=2)\n",
        "    #raise NotImplementedError\n",
        "    ############################################################################\n",
        "\n",
        "    return sensitivity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y6Lvqc8Ey5C",
        "colab_type": "text"
      },
      "source": [
        "main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_BUButIEy5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(n, runs, epochs, lr, batch_size, model_seed, lmbda):\n",
        "    list_of_empirical_sensitivies = []\n",
        "    list_of_neighboring_examples = []\n",
        "    for data_seed in range(runs):\n",
        "        loaders, neighboring_examples = get_data_loaders(data_seed, batch_size, \n",
        "                num_train=n)\n",
        "        sensitivity = compute_empricial_sensivity(\n",
        "                loaders['train'], loaders['neighbor'],\n",
        "                epochs, lr, lmbda, model_seed)\n",
        "        list_of_empirical_sensitivies.append(sensitivity)\n",
        "        list_of_neighboring_examples.append(neighboring_examples)\n",
        "\n",
        "    list_of_empirical_sensitivies = np.array(list_of_empirical_sensitivies)\n",
        "    sensitivity_upper_bound = 3.\n",
        "    name = 'lambda={},n={}'.format(lmbda, n)\n",
        "    filename = plot_hist(list_of_empirical_sensitivies, n, lmbda, name)\n",
        "    print('see plot at', filename)\n",
        "\n",
        "    filenames = plot_extreme_neighbors(list_of_empirical_sensitivies, list_of_neighboring_examples, name)\n",
        "    print('see plots at {} and {}'.format(*filenames))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-IgpdyLEy5F",
        "colab_type": "text"
      },
      "source": [
        "arguments and main function call"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFBvlm7MEy5G",
        "colab_type": "code",
        "outputId": "1ccc56fd-827a-4995-a935-bf701cc5a56b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "N = 1000\n",
        "RUNS = 4  # TODO(student): run more times once your code works; something like 100\n",
        "EPOCHS = 100\n",
        "LR = 0.1\n",
        "BATCH_SIZE = 256\n",
        "MODEL_SEED = 0\n",
        "LMBDA = 5e-4\n",
        "\n",
        "main(N, RUNS, EPOCHS, LR, BATCH_SIZE, MODEL_SEED, LMBDA)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a2af968e7ccd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mLMBDA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRUNS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_SEED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLMBDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-2b12c566858c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(n, runs, epochs, lr, batch_size, model_seed, lmbda)\u001b[0m\n\u001b[1;32m      7\u001b[0m         sensitivity = compute_empricial_sensivity(\n\u001b[1;32m      8\u001b[0m                 \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neighbor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 epochs, lr, lmbda, model_seed)\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mlist_of_empirical_sensitivies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlist_of_neighboring_examples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighboring_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-59f6e4bc881c>\u001b[0m in \u001b[0;36mcompute_empricial_sensivity\u001b[0;34m(train_loader, neighbor_loader, num_epochs, learning_rate, lmbda, model_seed)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# your code here...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mtrain_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonprivate_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mneighbor_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonprivate_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbor_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nonprivate_logistic_regression' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_42jbVYEy5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}