{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "empirical_sensitivity.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InesBi/fairness-and-privacy/blob/master/empirical_sensitivity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09zMyIxCEy44",
        "colab_type": "text"
      },
      "source": [
        "import statments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHU7nHAUE6LZ",
        "colab_type": "code",
        "outputId": "8fcb8434-08b7-4f5e-da01-2927f466e7c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "!git clone https://github.com/ecreager/ammi-fairness-and-privacy.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ammi-fairness-and-privacy'...\n",
            "remote: Enumerating objects: 113, done.\u001b[K\n",
            "remote: Counting objects: 100% (113/113), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 113 (delta 34), reused 90 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (113/113), 27.11 MiB | 43.11 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PmUheTwFB0l",
        "colab_type": "code",
        "outputId": "e54733e0-0164-4724-8d20-f66a54a2543e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/ammi-fairness-and-privacy/assignment2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ammi-fairness-and-privacy/assignment2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D7aa5mUEy46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Empirical Sensitivity.\"\"\"\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from utils import get_data_loaders\n",
        "from logistic_regression import nonprivate_logistic_regression\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0DqweckEy4-",
        "colab_type": "text"
      },
      "source": [
        "your code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITJ2VOVdEy4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_hist(array_of_empirical_sensitivities, n, lmbda, name):\n",
        "    if not isinstance(array_of_empirical_sensitivities, np.ndarray):\n",
        "        raise ValueError('array_of_empirical_sensitivities should be a np.ndarray.')\n",
        "    if not isinstance(name, str):\n",
        "        raise ValueError('name should be a str')\n",
        "\n",
        "    import matplotlib\n",
        "    matplotlib.use('Agg')\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    ################################################################\n",
        "    # TODO(student): replace below with correct theoretical max sensitivity\n",
        "    max_theoretical_sensitivity = -1.\n",
        "    ################################################################\n",
        "\n",
        "    num_bins = 20\n",
        "    dirname = './figs'\n",
        "    filename = os.path.join(dirname, name) + '.histogram.png'\n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_xscale('log')\n",
        "    bin_values, _, _ = ax.hist(array_of_empirical_sensitivities, \n",
        "            num_bins, label='empirical sensitivities')\n",
        "    ax.set_title('histogram of sensitivities: ' + name)\n",
        "    ax.axvline(x=max_theoretical_sensitivity, color='r', linestyle='dashed', linewidth=2,\n",
        "            label='theoretical max sensitivity')\n",
        "    ax.legend()\n",
        "    fig.savefig(filename)\n",
        "    return filename\n",
        "\n",
        "\n",
        "def plot_extreme_neighbors(sensitivities, list_of_neighboring_examples, name):\n",
        "    \"\"\"Plots to disk the neighboring-example pairs with the most and least empirical sensitivity\n",
        "    \n",
        "    Note on the data structures used: \n",
        "        sensitivities: a np.ndarray containing empirical sensitivities for each run\n",
        "        list_of_neighboring_examples: a list of neighboring example pairs, one for each run. in other words:\n",
        "        \n",
        "        list_of_neighboring_examples = [\n",
        "            neighboring_example_1, \n",
        "            neighboring_example_2,  \n",
        "            ...\n",
        "            neighboring_example_n,\n",
        "            ]\n",
        "            \n",
        "        where each tuple in the list represents the data diff between the neighboring \n",
        "        datasets and is formatted like this:\n",
        "        \n",
        "        neighboring_example_i = (\n",
        "            (neighbor_img_i, neighbor_label_i),\n",
        "            (neighbor_img_i_prime, neighbor_label_i_prime),\n",
        "        )\n",
        "        \n",
        "        See utils.py if you are still confused.\n",
        "    \"\"\"\n",
        "    if not isinstance(sensitivities, np.ndarray):\n",
        "        raise ValueError('sensitivies should be a np.ndarray.')\n",
        "    first_neighbor_pair = list_of_neighboring_examples[0]\n",
        "    if not isinstance(list_of_neighboring_examples, list) or not isinstance(first_neighbor_pair, tuple) \\\n",
        "            or not isinstance(first_neighbor_pair[0][0], torch.Tensor):\n",
        "        raise ValueError('list_of_neighboring_examples should be a list of tuple pairs, where tuple contains img tensors')\n",
        "    if not isinstance(name, str):\n",
        "        raise ValueError('name should be a str')\n",
        "\n",
        "    import matplotlib\n",
        "    matplotlib.use('Agg')\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO(student)\n",
        "    #\n",
        "    # using list_of_empirical_sensitivies and neighboring_examples, create two image plots\n",
        "    # 1) side-by-side images for neighbor-pair that maximizes sensitivity\n",
        "    # 2) side-by-side images for neighbor-pair that minimizes sensitivity\n",
        "    #\n",
        "    # matplotlib.subplots and matplotlib.imshow may come in handy\n",
        "    \n",
        "    #filenames = None, None\n",
        "    #raise NotImplementedError\n",
        "    pil_transform = transforms.ToPILImage()\n",
        "    max_idx = np.argmax(sensitivities)\n",
        "    min_idx = np.argmin(sensitivities)\n",
        "    max_neighbor_example = list_of_neighboring_examples[max_idx]\n",
        "    min_neighbor_example = list_of_neighboring_examples[min_idx]\n",
        "    max_neighbor, max_neighbor_prime = max_neighbor_example\n",
        "    min_neighbor, min_neighbor_prime = min_neighbor_example\n",
        "    \n",
        "    max_neighbor_img, max_neighbor_target = max_neighbor\n",
        "    max_neighbor_prime_img, max_neighbor_prime_target = max_neighbor_prime\n",
        "    \n",
        "    min_neighbor_img, min_neighbor_target = min_neighbor\n",
        "    min_neighbor_prime_img, min_neighbor_prime_target = min_neighbor_prime\n",
        "    \n",
        "    dirname = \"./figs\"\n",
        "    filename1 = os.path.join(dirname, name) + \".max_sensitivity.png\"\n",
        "    filename2 = os.path.join(dirname, name) + \".min_sensitivity.png\"\n",
        "    filenames = filename1, filename2\n",
        "    \n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)\n",
        "    fig1, axes1 = plt.subplots(1,2,figsize=(9,3))\n",
        "    axes1[0].imshow(pil_transform(max_neighbor_img))\n",
        "    axes1[1].imshow(pil_transform(max_neighbor_prime_img))\n",
        "    fig1.suptitle(\"maximum sensitivity:\" + name)\n",
        "    fig1.savefig(filename1)\n",
        "    \n",
        "    \n",
        "    fig2, axes2 = plt.subplots(1,2,figsize = (9,3))\n",
        "    axes2[0].imshow(pil_transform(min_neighbor_img))\n",
        "    axes2[1].imshow(pil_transform(min_neighbor_prime_img))\n",
        "    fig2.suptitle(\"minimum sensitivity:\" + name)\n",
        "    fig2.savefig(filename2)\n",
        "    ############################################################################\n",
        "\n",
        "    return filenames\n",
        "\n",
        "\n",
        "def compute_empricial_sensivity(train_loader, neighbor_loader,\n",
        "        num_epochs, learning_rate, lmbda, model_seed=None):\n",
        "    ############################################################################\n",
        "    # TODO(student)\n",
        "    #\n",
        "    # your code here...\n",
        "    #\n",
        "    train_param = nonprivate_logistic_regression(train_loader, num_epochs, learning_rate, lmbda,model_seed)\n",
        "    neighbor_param = nonprivate_logistic_regression(neighbor_loader, num_epochs, learning_rate, lmbda, model_seed)\n",
        "    \n",
        "    sensitivity = torch.norm(train_param[\"weight\"] - neighbor_param[\"weight\"], p=2)\n",
        "    #raise NotImplementedError\n",
        "    ############################################################################\n",
        "\n",
        "    return sensitivity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y6Lvqc8Ey5C",
        "colab_type": "text"
      },
      "source": [
        "main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_BUButIEy5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(n, runs, epochs, lr, batch_size, model_seed, lmbda):\n",
        "    list_of_empirical_sensitivies = []\n",
        "    list_of_neighboring_examples = []\n",
        "    for data_seed in range(runs):\n",
        "        loaders, neighboring_examples = get_data_loaders(data_seed, batch_size, \n",
        "                num_train=n)\n",
        "        sensitivity = compute_empricial_sensivity(\n",
        "                loaders['train'], loaders['neighbor'],\n",
        "                epochs, lr, lmbda, model_seed)\n",
        "        list_of_empirical_sensitivies.append(sensitivity)\n",
        "        list_of_neighboring_examples.append(neighboring_examples)\n",
        "\n",
        "    list_of_empirical_sensitivies = np.array(list_of_empirical_sensitivies)\n",
        "    sensitivity_upper_bound = 3.\n",
        "    name = 'lambda={},n={}'.format(lmbda, n)\n",
        "    filename = plot_hist(list_of_empirical_sensitivies, n, lmbda, name)\n",
        "    print('see plot at', filename)\n",
        "\n",
        "    filenames = plot_extreme_neighbors(list_of_empirical_sensitivies, list_of_neighboring_examples, name)\n",
        "    print('see plots at {} and {}'.format(*filenames))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-IgpdyLEy5F",
        "colab_type": "text"
      },
      "source": [
        "arguments and main function call"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFBvlm7MEy5G",
        "colab_type": "code",
        "outputId": "b9537340-4c96-4d2b-ce41-0cea531a11cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "N = 1000\n",
        "RUNS = 4  # TODO(student): run more times once your code works; something like 100\n",
        "EPOCHS = 100\n",
        "LR = 0.1\n",
        "BATCH_SIZE = 256\n",
        "MODEL_SEED = 0\n",
        "LMBDA = 5e-4\n",
        "\n",
        "main(N, RUNS, EPOCHS, LR, BATCH_SIZE, MODEL_SEED, LMBDA)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 28054893.37it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 437002.24it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 144242.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7137850.26it/s]                           \n",
            "8192it [00:00, 185118.92it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:11<00:00,  8.42it/s]\n",
            "100%|██████████| 100/100 [00:10<00:00,  9.37it/s]\n",
            "100%|██████████| 100/100 [00:09<00:00, 10.50it/s]\n",
            "100%|██████████| 100/100 [00:09<00:00, 10.38it/s]\n",
            "100%|██████████| 100/100 [00:09<00:00,  9.23it/s]\n",
            "100%|██████████| 100/100 [00:09<00:00, 10.45it/s]\n",
            "100%|██████████| 100/100 [00:09<00:00, 10.40it/s]\n",
            "100%|██████████| 100/100 [00:09<00:00, 10.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "see plot at ./figs/lambda=0.0005,n=1000.histogram.png\n",
            "see plots at ./figs/lambda=0.0005,n=1000.max_sensitivity.png and ./figs/lambda=0.0005,n=1000.min_sensitivity.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_42jbVYEy5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}